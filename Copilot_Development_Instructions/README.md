---
applyTo: "jarvis/**,tests/**,Diagnostics/**"
---

# START HERE: Copilot Instructions for Jarvis Development Repo

**READ THIS FIRST** if you are a Copilot or AI agent working in the **actual Jarvis development repository**.

---

## What is This?

You are building **Jarvis Cluster v0.1** â€” the minimum viable product.

This folder contains instructions that guide your actual implementation work. These instructions come from the **design repository** (`JarvisCluster_Development`) where the plan was created.

**Important**: There is a **separate design repository** that prepared this entire plan. You are in the **production/development repository**. Don't go looking for the design repoâ€”just follow these instructions.

---

## Your Mission

Follow the step-by-step development plan **exactly**. Implement one step at a time:

1. **Step 1**: Basic CLI
2. **Step 2**: Graph/Node/Edge
3. **Step 3**: Folder Observation
4. **Step 3.2**: Function Observation
5. **Step 4.1**: Test Functions
6. **Step 4.2**: Execution Engine

When v0.1 is complete, you'll have a working Jarvis that can:
- âœ… Accept CLI commands
- âœ… Represent structures as graphs
- âœ… Observe its own codebase
- âœ… Execute chains of functions

---

## The Workflow for EACH Step

This is criticalâ€”follow this process for every single step:

1. **Read** â€” Read the ENTIRE step file (in `Agent_Workspace/`)
2. **Understand** â€” Understand all requirements
3. **Design** â€” Design the data structures and functions
4. **Test First** â€” Write ALL tests before ANY implementation
5. **Implement** â€” Write code to pass the tests
6. **Verify** â€” Run tests locally
7. **Confirm** â€” Ask Owen to confirm the step is complete
8. **Move** â€” Don't move to the next step until Owen approves

**TDD is mandatory**: Tests ALWAYS come before implementation.

---

## File Structure

You have been given:

```
Agent_Workspace/
â”œâ”€â”€ step_1_basic_cli.md              (detailed step 1 instructions)
â”œâ”€â”€ step_2_graph_nodes_edges.md      (detailed step 2 instructions)
â”œâ”€â”€ step_3_observation_folders.md    (detailed step 3 instructions)
â”œâ”€â”€ step_3_2_observation_functions.md (detailed step 3.2 instructions)
â”œâ”€â”€ step_4_1_test_functions.md       (detailed step 4.1 instructions)
â”œâ”€â”€ step_4_2_execution_engine.md     (detailed step 4.2 instructions)
â”œâ”€â”€ ode Organization Rules

Your code must follow this **exact** structure:

```
jarvis/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ cli.metadata.json
â”‚   â””â”€â”€ cli_Test.py
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ graph.py
â”‚   â”œâ”€â”€ graph.metadata.json
â”‚   â””â”€â”€ graph_Test.py
â”œâ”€â”€ observers/
â”‚   â”œâ”€â”€ observers.py
â”‚   â”œâ”€â”€ observers.metadata.json
â”‚   â””â”€â”€ observers_Test.py
â”œâ”€â”€ test_functions/
â”‚   â”œâ”€â”€ test_functions.py
â”‚   â”œâ”€â”€ test_functions.metadata.json
â”‚   â””â”€â”€ test_functions_Test.py
â”œâ”€â”€ execution/
â”‚   â”œâ”€â”€ execution.py
â”‚   â”œâ”€â”€ execution.metadata.json
â”‚   â””â”€â”€ execution_Test.py
â””â”€â”€ Diagnostics/
    â””â”€â”€ test_suit.py
```

**Rules**:
- One main implementation file per folder
- One test file per folder (same folder as implementation)
- One metadata JSON file per module
- Test file name format: `module_name_Test.py`
- Metadata file name format: `module_name.metadata.json`

---

## Testing Approach

Testing is **critical** to v0.1 success:

### Test-Driven Development (TDD)
1. **Write tests first** â€” Before any implementation
2. **Tests define behavior** â€” Tests are your specification
3. **Tests must pass** â€” All tests must pass before moving to next step
4. **No cherry-picking** â€” Implement everything the tests require, no more, no less

### Running Tests
```bash
# Run all tests
pytest tests/test_step_*.py -v

# Run tests for a specific step
pytest tests/test_step_1.py -v

# Run the master test suite
python Diagnostics/test_suit.py
```

### Test File Location
- Test files live **alongside** implementation files
- Example: `graph.py` and `graph_Test.py` in same folder
- Use pytest framework

---

## Metadata Files

Every module has a `.metadata.json` file describing it:

```json
{
  "general": {
    "name": "module_name",
    "description": "What this module does",
    "version": "0.1",
    "status": "in-development"
  },
  "implementation": {
    "file": "module_name.py",
    "status": "in-progress",
    "completion_percentage": 50
  },
  "testing": {
    "file": "module_name_Test.py",
    "status": "tests-ahead",
    "test_count": 10,
    "passing_tests": 0,
    "failing_tests": 10
  },
  "functions": [],
  "dependencies": [],
  "copilot_notes": ""
}
```

See `DESIGN_REFERENCE/Metadata_Design.md` for full details.

---

## Critical Rules

### âœ… DO
- Write tests before implementation
- Follow the step-by-step plan exactly
- Keep functions small (< 500 lines per file)
- Use only Python stdlib (no external packages unless specified)
- Create METADATA files as specified
- Ask Owen before skipping anything
- Confirm with Owen after each step

### âŒ DON'T
- Skip steps or jump ahead
- Implement "future features"
- Copy code from any Sandbox repo
- Add error handling beyond what's specified
- Create files outside the designed structure
- Assume anythingâ€”if unclear, ask Owen
- Move to the next step without Owen approval

---

## The TDD Cycle (Repeat for Each Step)

```
1. READ step file
   â†“
2. WRITE tests (all of them, before any code)
   â†“
3. RUN tests (they will failâ€”expected)
   â†“
4. IMPLEMENT code to pass tests
   â†“
5. RUN tests again (they should pass)
   â†“
6. MANUAL test via CLI (if applicable)
   â†“
7. ASK OWEN to confirm
   â†“
8. NEXT STEP (only after Owen approves)
```

---

## When You Get Stuck

1. **Re-read the step file** â€” Very detailed, answer is likely there
2. **Check test requirements** â€” Tests define expected behavior exactly
3. **Look at design reference** â€” Folder structure, metadata format, etc.
4. **Ask Owen** â€” Before proceeding or making assumptions

---

## Success Criteria for v0.1

When all 6 steps are complete:

- [ ] All tests pass
- [ ] All steps confirmed by Owen
- [ ] Code follows all guidelines
- [ ] METADATA files created for all modules
- [ ] CLI works interactively
- [ ] Code is clean and readable
- [ ] No extra features beyond each step's specification
- [ ] No external dependencies (stdlib only)
- [ ] No Sandbox code used

---

## Important Notes

### Zero Time Pressure
- Complete means **100% correct**, not fast
- No rushâ€”quality over speed
- Better to do less perfectly than more poorly

### Tests Are Your Spec
- If tests pass, you're done
- Don't implement beyond what tests require
- Tests stay ahead of implementation (TDD)

### Communication
- Confirm with Owen after each step
- Ask questions before guessing
- Don't move forward without approval

### Code Quality
- One class per file
- < 500 lines per file
- Clear, readable naming
- Docstrings on classes and functions
- Type hints where applicable

---

## Next Steps

1. Open the **first step file** in `Agent_Workspace/`
2. Read it completely
3. Understand all requirements
4. Start the TDD cycle above

Good luck! Remember: **Tests first, implementation second.**

## Next Step

1. Read the current step file
2. Understand the requirements
3. Write tests
4. Implement
5. Confirm with Owen
6. Repeat

Good luck! ðŸš€

