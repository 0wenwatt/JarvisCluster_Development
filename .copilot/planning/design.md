# Design & Architecture

**Parent**: [Planning Index](index.md)  
**Level**: 3 (Topic Detail)

---

## ğŸ“‹ Summary

This document provides a summary of Jarvis system architecture, component design, and technical decisions. It consolidates information from DESIGN_PLAN.md and related architectural documents.

---

## ğŸ—ï¸ System Architecture

### High-Level Overview

Jarvis is a cluster management system with a distributed architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Control Plane                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Scheduler  â”‚  â”‚  Orchestratorâ”‚  â”‚    Monitor   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Worker Nodes        â”‚  â”‚    Data Layer         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Node â”‚  â”‚ Node â”‚ ... â”‚  â”‚  â”‚ Stateâ”‚  â”‚ Logs â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Core Components

### 1. API Layer
**Purpose**: External interface for cluster interaction  
**Priority**: P0 (MVP Critical)  
**Technology**: FastAPI (Python)

**Responsibilities**:
- Accept and validate HTTP requests
- Route requests to appropriate handlers
- Return formatted responses
- Handle authentication (P2)
- Rate limiting (P2)

**Key Endpoints**:
- `POST /tasks` - Submit task
- `GET /tasks/{id}` - Get task status
- `GET /health` - Health check
- `GET /nodes` - List worker nodes (P1)

**Location in Implementation**: `jarvis/api/`

---

### 2. Scheduler
**Purpose**: Intelligent task distribution and workload balancing  
**Priority**: P0 (basic), P1-P2 (advanced)  
**Technology**: Python with asyncio

**Responsibilities**:
- Maintain task queue (FIFO initially, priority later)
- Match tasks to available worker nodes
- Load balancing across nodes
- Handle scheduling policies
- Retry failed tasks

**Key Algorithms**:
- Resource matching (P0): Find nodes with sufficient resources
- Load balancing (P1): Round-robin, least-loaded
- Priority scheduling (P2): Priority queue with preemption
- Bin packing (P2): Optimize resource utilization

**Location in Implementation**: `jarvis/scheduler/`

---

### 3. State Manager
**Purpose**: Centralized state tracking and persistence  
**Priority**: P0 (in-memory), P1 (persistent)  
**Technology**: In-memory (Phase 1), etcd (Phase 3)

**Responsibilities**:
- Track all tasks and their states
- Maintain node registry
- Store cluster configuration
- Provide state queries
- Handle persistence

**State Tracked**:
- Task metadata and status
- Worker node registry and health
- Cluster configuration
- Historical data (P2)

**Location in Implementation**: `jarvis/state/`

---

### 4. Worker
**Purpose**: Task execution on individual nodes  
**Priority**: P0 (basic execution), P1 (monitoring)  
**Technology**: Python with Docker API

**Responsibilities**:
- Register with scheduler
- Execute assigned tasks in containers
- Monitor local resource usage
- Report task status
- Send heartbeats

**Execution Flow**:
1. Receive task assignment
2. Pull container image
3. Create and start container
4. Monitor execution
5. Report completion/failure
6. Cleanup resources

**Location in Implementation**: `jarvis/worker/`

---

### 5. Monitor
**Purpose**: Health tracking and observability  
**Priority**: P1 (basic), P2 (full observability)  
**Technology**: Python with Prometheus

**Responsibilities**:
- Heartbeat monitoring
- Detect node failures
- Collect metrics
- Generate alerts
- Export to Prometheus

**Metrics Collected**:
- Node health and availability
- Task execution stats
- Resource utilization
- Scheduler performance
- System throughput

**Location in Implementation**: `jarvis/monitor/`

---

### 6. DAG Manager
**Purpose**: Workflow and dependency management  
**Priority**: P2 (Advanced feature)  
**Technology**: Python with graph algorithms

**Responsibilities**:
- Parse DAG definitions
- Validate DAG structure (no cycles)
- Resolve task dependencies
- Schedule tasks in correct order
- Handle partial failures

**Location in Implementation**: `jarvis/dag/`

---

## ğŸ”§ Technology Stack

### Core Technologies
- **Language**: Python 3.9+
- **API Framework**: FastAPI
- **Async Runtime**: asyncio
- **Container Runtime**: Docker
- **State Storage**: 
  - Phase 1: In-memory (Python dict)
  - Phase 3: etcd or Consul
- **Message Queue**: Redis Streams or RabbitMQ (P1)

### Supporting Technologies
- **Metrics**: Prometheus + Grafana (P2)
- **Logging**: Python logging with structured output (P0)
- **Configuration**: YAML files (P0)
- **Testing**: pytest (P0)
- **Deployment**: Docker, Kubernetes (P2)

---

## ğŸ”„ Data Flows

### Task Submission Flow
```
Client
  â†“ POST /tasks
API Server
  â†“ Validate & enqueue
Scheduler (Task Queue)
  â†“ Match resources
Resource Matcher
  â†“ Select node
Worker Node
  â†“ Execute in container
Task Executor
  â†“ Report status
State Manager
  â†“ Update state
API Server
  â†“ GET /tasks/{id}
Client
```

### Heartbeat Flow
```
Worker Node
  â†“ Periodic heartbeat
Monitor (Heartbeat Listener)
  â†“ Update last seen
State Manager (Node Registry)
  â†“ Check threshold
Monitor (Failure Detector)
  â†“ If timeout
Scheduler (Task Recovery)
  â†“ Reschedule tasks
Available Nodes
```

---

## ğŸ¯ Design Principles

### 1. Distributed by Default
- No single point of failure
- Leader election for control plane (P3)
- Data replication across nodes (P3)

### 2. API-First Design
- All functionality via REST APIs
- Clear versioning (v1, v2, etc.)
- Comprehensive OpenAPI docs

### 3. Container-Native
- All tasks run in containers
- Docker as execution environment
- Kubernetes-compatible (future)

### 4. Modular Architecture
- Clear component boundaries
- Pluggable schedulers (P2)
- Extensible via plugins (P3)

### 5. Cloud-Agnostic
- No cloud-specific dependencies (P0-P1)
- Multi-cloud support (P3)
- On-premise friendly

---

## ğŸ“Š Component Dependencies

```
Build/Test Order:
1. utils â†’ exceptions â†’ constants
2. state (memory backend) â†’ config
3. scheduler (basic) â†’ state
4. worker â†’ scheduler communication
5. api â†’ scheduler + state
6. monitor â†’ scheduler + worker
7. dag â†’ scheduler
```

---

## ğŸ”— Detailed Documentation

For complete architectural details, see:
- **Full Design**: [/DESIGN_PLAN.md](../../DESIGN_PLAN.md)
- **Use Cases**: [/USE_CASES.md](../../USE_CASES.md)
- **Architecture Docs**: [/docs/architecture/](../../docs/architecture/)
- **ADRs**: [/docs/adr/](../../docs/adr/)

For implementation structure:
- **File Tree**: [/JARVIS_FILE_TREE.md](../../JARVIS_FILE_TREE.md)
- **Implementation Guide**: [../implementation/core-components.md](../implementation/core-components.md)

---

**Source Documents**: DESIGN_PLAN.md, docs/architecture/, docs/adr/  
**Last Updated**: 2026-01-08  
**Status**: Current as of Phase 0  
**Next**: Return to [Planning Index](index.md) or [Main Index](../INDEX.md)
